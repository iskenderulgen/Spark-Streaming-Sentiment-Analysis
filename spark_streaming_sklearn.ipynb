{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2330a94e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "from pyspark.sql import SparkSession\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import re\n",
    "from tqdm.notebook import tqdm\n",
    "from pyspark.sql.types import (\n",
    "    StructType,\n",
    "    StructField,\n",
    "    StringType,\n",
    ")\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "nltk.download(\"punkt_tab\")\n",
    "nltk.download(\"stopwords\")\n",
    "\n",
    "spark = (\n",
    "    SparkSession.builder.master(\"local[*]\")\n",
    "    .appName(\"Structured-Streaming\")\n",
    "    .config(\"spark.driver.memory\", \"4g\")\n",
    "    .getOrCreate()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ecb94c",
   "metadata": {},
   "source": [
    "# 1- Embeddings and Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78ab15e8",
   "metadata": {},
   "source": [
    "## Load Glove Embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812344a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_index = {}\n",
    "\n",
    "with open(\"data/glove.6B.50d.txt\", \"r\", encoding=\"utf8\") as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vector = np.asarray(values[1:], dtype=\"float32\")\n",
    "        embeddings_index[word] = vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a65bd7",
   "metadata": {},
   "source": [
    "## Normalization function for cleaning and tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2001f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_text(text):\n",
    "    # Regex to remove URLs, special characters, and extra spaces\n",
    "    text = re.sub(r\"[\\r\\n]+|https?://\\S+|[^a-zA-Z0-9\\s]\", \" \", text)\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words (optional)\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76467028",
   "metadata": {},
   "source": [
    "## Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66de9e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_embedding(text, embeddings_index, embedding_dim=50):\n",
    "    # Normalize text\n",
    "    tokens = normalize_text(text)\n",
    "    # Convert tokens to embeddings\n",
    "    vectors = [embeddings_index.get(token, np.zeros(embedding_dim)) for token in tokens]\n",
    "    if vectors:\n",
    "        return np.mean(vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2892fe4f",
   "metadata": {},
   "source": [
    "# 2-Train Logistic Regression for Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc214a54",
   "metadata": {},
   "source": [
    "## Read IMDB Sentiment Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11e9d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_dataset = pd.read_parquet(\"data/train-imdb.parquet\")\n",
    "\n",
    "imdb_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dd9c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tqdm for pandas\n",
    "tqdm.pandas(desc=\"Creating embeddings\")\n",
    "\n",
    "# Apply the function on the 'text' column with a progress bar\n",
    "imdb_dataset[\"embedding\"] = imdb_dataset[\"text\"].progress_apply(\n",
    "    lambda x: sentence_embedding(x, embeddings_index)\n",
    ")\n",
    "\n",
    "imdb_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76a8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, stack your embeddings into a 2D array\n",
    "X = np.stack(imdb_dataset[\"embedding\"].values)\n",
    "y = imdb_dataset[\"label\"].values\n",
    "\n",
    "# Perform stratified train-test split (e.g., 80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d4764ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(n_jobs=-1, max_iter=100).fit(X_train, y_train)\n",
    "\n",
    "# Optionally you can save the model using joblib or pickle\n",
    "# joblib.dump(model, 'data/logistic_regression_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ff3659",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on test set\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred):.4f}\")\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce5959a",
   "metadata": {},
   "source": [
    "# 3-Spark Structured Streaming for Text Classification\n",
    "## Plotting and Embedding Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54dfe5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage for batch-wise counts\n",
    "batch_pos_counts, batch_neg_counts, batch_ids = [], [], []\n",
    "\n",
    "# Create a function to plot both the trend and current batch pie chart\n",
    "def plot_sentiment(pos_count, neg_count, batch_id):\n",
    "    # Set up a figure with two subplots - line chart and pie chart\n",
    "    plt.figure(figsize=(16, 6))\n",
    "    \n",
    "    # Line plot showing trends over batches (left subplot)\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(batch_ids, batch_pos_counts, 'g-o', label=\"Positive\")\n",
    "    plt.plot(batch_ids, batch_neg_counts, 'r-o', label=\"Negative\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.title(\"Sentiment Analysis Results by Batch\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.ylim(bottom=0)\n",
    "    \n",
    "    # Pie chart for current batch (right subplot)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    labels = ['Positive', 'Negative']\n",
    "    sizes = [pos_count, neg_count]\n",
    "    colors = ['green', 'red']\n",
    "    plt.pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "    plt.axis('equal')  # Equal aspect ratio ensures the pie is circular\n",
    "    plt.title(f\"Batch {batch_id} Sentiment Distribution\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Display and ensure it stays visible\n",
    "    clear_output(wait=True)\n",
    "    plt.show()\n",
    "\n",
    "def process_batch(batch_df, batch_id):\n",
    "    pdf = batch_df.toPandas()\n",
    "    if pdf.empty:\n",
    "        print(f\"Batch {batch_id}: Empty batch\")\n",
    "        return\n",
    "    \n",
    "    # Vectorize and predict\n",
    "    pdf[\"embedding\"] = pdf[\"text\"].apply(lambda x: sentence_embedding(x, embeddings_index))\n",
    "    X_batch = np.stack(pdf[\"embedding\"].values)\n",
    "    y_pred = model.predict(X_batch)\n",
    "    \n",
    "    # Count positives and negatives\n",
    "    pos_count = np.sum(y_pred == 1)\n",
    "    neg_count = np.sum(y_pred == 0)\n",
    "    batch_pos_counts.append(pos_count)\n",
    "    batch_neg_counts.append(neg_count)\n",
    "    batch_ids.append(batch_id)\n",
    "    \n",
    "    # Create and display plots\n",
    "    plot_sentiment(pos_count, neg_count, batch_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409402bb",
   "metadata": {},
   "source": [
    "## Spark Structured Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5791417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the streaming source\n",
    "yelp_stream = (\n",
    "    spark.readStream.format(\"parquet\")\n",
    "    .schema(StructType([StructField(\"text\", StringType(), True)]))\n",
    "    .option(\"maxFilesPerTrigger\", 1)\n",
    "    .load(\"data/yelp/\")\n",
    ")\n",
    "\n",
    "# Start the streaming query\n",
    "query = (\n",
    "    yelp_stream.writeStream\n",
    "    .foreachBatch(process_batch)\n",
    "    .outputMode(\"append\")\n",
    "    .start()\n",
    ")\n",
    "\n",
    "try:\n",
    "    query.awaitTermination(timeout=600)\n",
    "    print(\"Query terminated after timeout\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Query terminated due to: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sparknlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
